---
title: "HWC"
author: "Roshni Katrak-Adefowora"
date: "11/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
library(tidyverse)
library(rgbif)
library(maptools)
library(dismo)
library(rgeos)
library(viridis)
#library(scrubr)
library(raster)
library(DHARMa)
library(spocc)
library(sf)
library(rgdal)
library(spData)
library(here)
library(lubridate)
library(kableExtra)

#install wallace
library(wallace)
run_wallace()

#load Wallace functions
source(system.file('shiny/funcs', 'functions.R', package = 'wallace'))
```

## Description:

This markdown file outlines methods that can be used to create data for species distribution modeling (SDM) with the Maxent GUI.

The Maxent GUI can be run two different ways:

  1) Using samples with data (SWD) where you extract the climate data from the bioclim rasters for each occurrence and background point.
  
  2) Using lat/long for each point and the bioclim rasters.

### Read in species occurrence data. For data wrangling methods, see hwc_wrangle_occurrence_inputs.Rmd.

Choose line to run depending on species & period
```{r}
occs <- read_csv("H:/My Drive/HWC/R_files/R_output_data/occurrence_points/lion_all_points_thinned.csv")
occs <- read_csv("H:/My Drive/HWC/R_files/R_output_data/occurrence_points/lion_bioclim_points_thinned.csv")
occs <- read_csv("H:/My Drive/HWC/R_files/R_output_data/occurrence_points/lion_chelsa_points_thinned.csv")
```


### Create background points

There are many ways to create background points. We tested creating background points with 1) one background point per pixel, 2) create background points within occurrence point buffers, and 3) using minimum convex polygons (following Wallace)

#### 2) Sample from witin buffers around occurrence points 

```{r}
#bgExt <- rgeos::gBuffer(bgExt, width = 0.5)

# create point buffers of 50 km
buffer_points <- circles(occs, d = 50000, lonlat = TRUE)

# getting random points from within our polygons
bg_points <-  spsample(buffer_points@polygons, 1000, type = 'random', iter = 1000)

```


### Load worldclim data and afrotropical region

```{r}
#read in worldclim version 2 data
rastlist <- list.files(path = "H:/My Drive/HWC/R_files/R_input_data/wc2.1_2.5m_bio", pattern='.tif$', full.names=TRUE)
bioclim_data_v2 <- stack(rastlist)

crs(bioclim_data_v2) <- "+proj=longlat +datum=WGS84 +no_defs"

#read in chelsa data
rastlist_chelsa <- list.files(path = "H:/My Drive/HWC/Data/Chelsa_Data/CHELSA_bio", pattern='.tif$', full.names=TRUE)
chelsa_data <- stack(rastlist_chelsa)

#get spatial extent using Afrotropical ecoregion from WWF. Data downloaded from https://www.worldwildlife.org/publications/terrestrial-ecoregions-of-the-world
afrotropical_region <- read_sf(dsn = "H:/My Drive/HWC/R_files/R_input_data/wwf_ecoregions/official", layer = "wwf_terr_ecos") %>% 
  filter(REALM == "AT")

#check crs
crs(afrotropical_region) # +proj=longlat +datum=WGS84 +no_defs 

# create shapefile for wallace
# st_write(afrotropical_region, dsn = "H:/My Drive/HWC/R_files/R_output_data/afrotropical_region/afrotropical_region.shp", layer = "afrotropical_region.shp", driver = "ESRI Shapefile")

# cropping bioclim variables to extent of Africa spatial polygon
bioclim_crop <- raster::crop(bioclim_data_v2, afrotropical_region)

# double checking to see they line up
plot(bioclim_crop[[1]])
plot(buffer_points, add = TRUE)

# extract environmental values at occ grid cells
locs.vals <- raster::extract(bioclim_crop[[1]], occs[, c('longitude', 'latitude')])

bioclim_selected <- raster::subset(bioclim_crop, c("wc2.1_2.5m_bio_1", "wc2.1_2.5m_bio_2", "wc2.1_2.5m_bio_5", "wc2.1_2.5m_bio_6", "wc2.1_2.5m_bio_12", "wc2.1_2.5m_bio_13", "wc2.1_2.5m_bio_14"))

bioclim_selected_extract <- raster::extract(bioclim_crop[[1]], occs[, c('longitude', 'latitude')])
# remove occs without environmental values
occs_ <- occs[!is.na(bioclim_selected_extract), ]
```

Find correlated bioclim variables
```{r}
bioclim_corr=layerStats(bioclim_selected_extract, 'pearson', na.rm=T)
corr_matrix=bioclim_corr$'pearson correlation coefficient'
corr_matrix[!corr_matrix > 0.75, ]
```

### LAT/LONG AND RASTER METHOD

```{r}
# Save occurrence point lat/long
lion_cleaned <- #coord_incomplete(coord_imprecise(coord_impossible(coord_unlikely(myspecies_coords))))%>%
  myspecies_coords %>% 
  rename(lat = latitude) %>% # renaming lat/long so it works with projection later on?
  rename(long = longitude)

lat_long <- lion_cleaned %>%
  dplyr::select(lat, long)

#add crs to bioclim variables for Wallace
 bio <- c(1:19) #vector for each bioclim variable
 for(i in bio){
         # Maxent reads either csv files or a directory -> need to export each bioclim raster separately
         writeRaster(bioclim_crop[[i]], 
                     filename = paste0("H:/My Drive/HWC/R_files/R_output_data/bioclim_v2/bio", i, ".asc"),
                     overwrite=TRUE)
 }
 
bioclim_crop_4326 <- projectRaster(bioclim_crop[[i]],
                                       crs = 4326)



# Save lat/long
 # write_csv(lat_long, "H:/My Drive/HWC/R_files/R_output_data/lat_lon/bioclim_lion_coords.csv")
           
# Download full raster layer for each bioclim variable for Maxent (may use in conjunction with bias layer)
 bio <- c(1:19) #vector for each bioclim variable
 for(i in bio){
         # Maxent reads either csv files or a directory -> need to export each bioclim raster separately
         writeRaster(bioclim_crop[[i]], 
                     filename = paste0("H:/My Drive/HWC/R_files/R_output_data/bioclim_v2/bio", i, ".asc"),
                     overwrite=TRUE)
 }
```


### SPECIES WITH DATA METHOD

Extract environmental data for occurrence and background points for species with data format for use with Maxent Gui

```{r}
# need just lat/long values in two columns to used raster extract
occs.xy <- occs[c('longitude', 'latitude')]
bg.xy <- as.data.frame(bg_points) # using buffer points for now

# extracting values
occ_extract <- raster::extract(bioclim_crop, occs.xy)
bg_extract <- raster::extract(bioclim_crop, bg.xy)

# saving as data frames, adding in data
occ_extract_final <- as.data.frame(occ_extract) %>% 
  mutate(latitude = occs.xy$latitude) %>% # adding long/lat back in
  mutate(longitude = occs.xy$longitude) %>% 
  mutate(species = "Panthera leo") %>% # adding species column
  dplyr::select(species, longitude, latitude, 1:19) # using select() to re-order columns
# 
# occ_extract_final_bio_sub <- occ_extract_final %>% 
#   dplyr::select(species, longitude, latitude, wc2.1_2.5m_bio_1, wc2.1_2.5m_bio_2, wc2.1_2.5m_bio_5, wc2.1_2.5m_bio_6, wc2.1_2.5m_bio_12, wc2.1_2.5m_bio_13, wc2.1_2.5m_bio_14) %>% 
#   summarize(mean = mean(wc2.1_2.5m_bio_1))

# for running correlation test
occ_extract_final_bio_sub_only <- occ_extract_final %>% 
  dplyr::select(wc2.1_2.5m_bio_1, wc2.1_2.5m_bio_2, wc2.1_2.5m_bio_5, wc2.1_2.5m_bio_6, wc2.1_2.5m_bio_12, wc2.1_2.5m_bio_13, wc2.1_2.5m_bio_14)

library(Hmisc)
occ_extract_final_bio_sub_matrix <- as.matrix(occ_extract_final_bio_sub_only)
rcorr(occ_extract_final_bio_sub_matrix, type="pearson") # type can be pearson or spearman

# get means 
chelsa_means <- colMeans(occ_extract_final_bio_sub_only, na.rm=TRUE)
chelsa_means_df <- data.frame(chelsa_means)
# write_csv(chelsa_means_df, "H:/My Drive/HWC/R_files/R_output_data/bioclim_variable_means/chelsa_pts_means.csv")

# get standard deviations
chelsa_sd <- occ_extract_final_bio_sub_only %>% 
summarise_if(is.numeric, sd, na.rm=TRUE)
# write_csv(chelsa_sd, "H:/My Drive/HWC/R_files/R_output_data/bioclim_variable_means/chelsa_pts_sd.csv")

# read in csv of 3 groups means and SDs
means_sds <- read_csv("H:/My Drive/HWC/R_files/R_output_data/bioclim_variable_means/combined_means_sd.csv")

kable(means_sds,
      col.names = c("Bioclim Variable", 
                    "All points means", 
                    "Bioclim means", 
                    "Chelsa means",
                    "All points sd", 
                    "Bioclim sd",
                    "Chelsa sd")) %>% 
  #row_spec(6, bold = T, color = "white", background = "green") %>% 
  kable_styling(bootstrap_options = "striped",
                full_width = FALSE)

bg_extract_final <- as.data.frame(bg_extract) %>% 
  mutate(x = bg.xy$x) %>% 
  mutate(y = bg.xy$y) %>% 
  mutate(species = "background") %>% 
  dplyr::select(species, x, y, 1:19) %>% 
  drop_na() # remove points with NA values

# # save csvs
# write_csv(occ_extract_final, "H:/My Drive/HWC/R_files/R_output_data/SWD/bioclim_lion_occ_SWD.csv")
# write_csv(bg_extract_final, "H:/My Drive/HWC/R_files/R_output_data/SWD/bioclim_lion_bg_SWD.csv")
```

### Chelsa - I think don't need to do this if follow same sections above for worldclim data
```{r}
# #read your file 
# r <- raster(system.file("data/chelsa/CHELSA_bio1_1981-2010_V.2.1.tif", package="raster")) 
# 
# #export it to asc (ESRI ASCII) 
# writeRaster(r, filename="bio1.asc", format = "ascii", datatype='INT4S', overwrite=TRUE)
# 
# #first import all files in a single folder as a list 
# rastlist <- list.files(path = here("data", "chelsa"), pattern='.tif$', all.files=TRUE, full.names=FALSE)
# 
# ftif <- list.files(path = here("data", "chelsa"), pattern='.tif$', full=TRUE)
# fasc <- gsub("\\.tif$", ".asc", ftif)
# 
# for (i in 1:length(ftif)) {
#     r <- raster(ftif[i])
#     r <- writeRaster(ftif[i],
#                      filename = paste0(here("data", "chelsa_asc", "chelsa"), i, ".asc"),
#                      overwrite=TRUE)
# }

###
f <- here("data", "chelsa", "CHELSA_bio1_1981-2010_V.2.1.tif")
r <- raster(f)
writeRaster(r, "C:/Users/roshn/OneDrive/Desktop/HWC/HWC/data/chelsa_asc/chelsa_bio1.asc", format = "ascii", overwrite=T)


f2 <- here("data", "chelsa", "CHELSA_bio2_1981-2010_V.2.1.tif")
r2 <- raster(f)
#ra2 <- aggregate(r, fact=2)  ## By default aggregates using mean, but see fun=
writeRaster(r2, "C:/Users/roshn/OneDrive/Desktop/HWC/HWC/data/chelsa_asc/chelsa_bio2.asc", format = "ascii", overwrite=T)

f5 <- here("data", "chelsa", "CHELSA_bio5_1981-2010_V.2.1.tif")
r5 <- raster(f)
writeRaster(r5, "C:/Users/roshn/OneDrive/Desktop/HWC/HWC/data/chelsa_asc/chelsa_bio5.asc", format = "ascii", overwrite=T)


# 
# #try looping it
# chelsa_bio <- c(1:19) #vector for each bioclim variable
# for(i in chelsa_bio){
#         # Maxent reads either csv files or a directory -> need to export each bioclim raster separately
#         writeRaster(ftif[[i]], 
#                     filename = paste0(here("data", "chelsa_asc", "bio"), i, ".asc"),
#                     overwrite=TRUE)
# }
```

### Land Cover Data - not doing for now

Downloaded from: http://due.esrin.esa.int/page_globcover.php

Reclassified following 

```{r}
#import downloaded ESA GlobCover 2009 file
land <- here("data", "Globcover2009_V2.3_Global_", "GLOBCOVER_L4_200901_200912_V2.3.tif")
land = raster(land)

#crop to Africa polygon
land_crop <- crop(land, africa_spatial)

# create land cover class values matrix for reclassification (see GlobCover2009_Legend.xls in downloaded cover data for id values and corresponding cover labels)
mtrx <- rbind(c(0, 21, 1), c(22, 91, 2), c(92, 101, 3), c(102, 121, 4), c(122, 161, 3),
              c(162, 171, 2), c(172, 181, 3), c(182, 260, 5)) #why don't values match spreadsheet?

#reclassify to broader categories: ag, grassland, forest, etc.
mtrx_test <- rbind(c(11, 14, 1), c(20, 30, 2), c(40, 50, 3), c(60, 70, 4), c(90, 100, 3),
              c(110, 120, 2), c(130, 140, 3), c(150, 160, 5)) #see if it works with matching values

land_rcl <- reclassify(land_crop, mtrx)

#crop to same extent as other layers for maxent
#land_rcl <- crop(land_rcl, bioclim_data, snap = "near") 
land_rcl <- crop(land_crop, bioclim_data, snap = "near") #changed land_rcl to land_crop for now since land_rcl isn't working
land_rcl <- raster::resample(land_rcl, bio_new[[1]], method = "ngb")

#write raster
writeRaster(land_rcl, "C:/Users/roshn/OneDrive/Desktop/emLab/hwc/maxent_SWD/bio_layers/bias_extent/esa_landcover.asc", format="ascii", overwrite = T)
```


### Bias Layers

```{r}




```


### Future Climate Data

This is just the basic way to download it and extract values, we didn't do anything further than this.

#### Download predicted climate rasters

```{r}
future_data <- getData('CMIP5',
                       var = "bio",
                       res = 2.5, 
                       rcp = 85, 
                       model = 'AC', 
                       year = 70)

# need names to match up to our preset-time climate data
names(future_data) <- names(bioclim_data)

# cropping to Africa polygon (not sure if we really need to, but might make it go faster)
future_data_crop <- raster::crop(future_data, africa_spatial)
```

#### Extracting predicted climate variables

- Do we only need to do the occurrence points?
- does it need the long/lat again? Or does it want x/y?

```{r}
# extracting values
occ_future_extract <- raster::extract(future_data_crop, occs.xy)

# saving as data frame, add long/lat back in, re-order
occ_extract_future_final <- as.data.frame(occ_future_extract) #should this be occ_future_extract instead of occ_extract?
# %>% 
  # mutate(latitude = occs.xy$latitude) %>% 
  # mutate(longitude = occs.xy$longitude) %>% 
  # dplyr::select(longitude, latitude, 1:19)

# save csv
write_csv(occ_extract_future_final, "lion_future_SWD.csv")
```

At this point, the SWD data files can be used to make prediction in the Maxent GUI, or used for modeling in R.


### SDM modeling in R

You can also do SDM in R using the maxent() function from the dismo package instead of using Wallace or the Maxent GUI, but we didn't investigate this very much because we had trouble getting rJava to work.  If you decide to go this route and also have trouble with rJava, try downloading the current Java Developer Kit from oracle.com 

https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html


```{r}
 library(dismo)
#install.packages("rJava")
 library(rJava)
# 
#withhold 20% of the data for testing the model
 fold <- kfold(occ_extract_final, k = 5) # making 5 groups
 lion_test <- occ_extract_final[fold == 1, ] #20% data
 lion_train <- occ_extract_final[fold != 1, ] #80% data
# 
# # making x argument
 predictions <- occ_extract_final %>%
   dplyr::select(bio1:bio19)
# 
# making p argument (just lat/long, )
 occurrence <- occ_extract_final %>%
   dplyr::select(longitude, latitude)
# 
 occurrence <- as.vector(occurrence)
# 
# making a argument
# # background <-
# 
# #fit the maxent model
 model <- maxent()
```

