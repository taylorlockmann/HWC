---
title: "Asian Elephant Occurrence Data"
author: "Grace Kumaishi"
date: "1/19/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
library(tidyverse)
library(rgbif) # interface to GBIF
library(maptools)
library(dismo)
library(rgeos)
library(viridis)
#library(scrubr)
library(raster)
#library(DHARMa) # something is wrong when I try to install/load
library(spocc) # Interface to species occurrence data sources
library(sf)
library(sp)
library(rgdal)
library(spData)
library(here)
library(lubridate)
library(kableExtra)
library(tmap)
library(here)
library(dplyr)
library(ggplot2)
library(ggbeeswarm)
library(patchwork)
#library(spThin)

#install wallace
library(wallace)

#load Wallace functions
source(system.file('shiny/funcs', 'functions.R', package = 'wallace'))
```

This does not need to be run again unless we're changing the input settings to create and thin our occurrence data. All occurrence results are saved as csv's and can be read in with the other Rmd.

## Description:

This markdown file outlines the first steps for creating data for species distribution modeling (SDM) with Wallace.

### Download species occurence data and get coordinates

We begin by downloading the species occurrence points for the Asian Elephant subspecies using Wallace's spocc:occ() function. Choose which chunk to run based on the species of interest.

Indian Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus indicus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus indicus")]]

# select just the necessary information
indicus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_indicus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

Sri Lankan Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus maximus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus maximus")]]

# select just the necessary information
maximus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_maximus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

Sumatran Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus sumatranus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus sumatranus")]]

# select just the necessary information
sumatranus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_sumatranus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

### Clean Data

```{r}
# remove rows with duplicate coordinates
occs.dups <- duplicated(indicus_coords[c('longitude', 'latitude')])
indicus_coords <- indicus_coords[!occs.dups,]

occs.dups <- duplicated(maximus_coords[c('longitude', 'latitude')])
maximus_coords <- maximus_coords[!occs.dups,]

occs.dups <- duplicated(sumatranus_coords[c('longitude', 'latitude')])
sumatranus_coords <- sumatranus_coords[!occs.dups,]

# make sure latitude and longitude are numeric (sometimes they are characters)
indicus_coords$latitude <- as.numeric(indicus_coords$latitude)
indicus_coords$longitude <- as.numeric(indicus_coords$longitude)

maximus_coords$latitude <- as.numeric(maximus_coords$latitude)
maximus_coords$longitude <- as.numeric(maximus_coords$longitude)

sumatranus_coords$latitude <- as.numeric(sumatranus_coords$latitude)
sumatranus_coords$longitude <- as.numeric(sumatranus_coords$longitude)

# give all records a unique ID
indicus_coords$occID <- row.names(indicus_coords)
maximus_coords$occID <- row.names(maximus_coords)
sumatranus_coords$occID <- row.names(sumatranus_coords)

# add species column to each dataset
indicus_coords$species <- "Indian elephant" 
  
indicus_coords <- indicus_coords %>% 
  relocate(species, .before = longitude)

maximus_coords$species <- "Sri Lankan elephant" 
  
maximus_coords <- maximus_coords %>% 
  relocate(species, .before = longitude)

sumatranus_coords$species <- "Sumatran elephant" 
  
sumatranus_coords <- sumatranus_coords %>% 
  relocate(species, .before = longitude)

# combine three species into single dataframe

all_spp_coords <- rbind(indicus_coords, maximus_coords, sumatranus_coords) 
```

### Crop data by species range

```{r}
# Turn data frames into sf object in order to crop by range shapefile
indicus_coords_sf <- st_as_sf(x = indicus_coords,
                              coords = c("longitude", "latitude"),
                              crs = 4326)

maximus_coords_sf <- st_as_sf(x = maximus_coords,
                              coords = c("longitude", "latitude"),
                              crs = 4326)

sumatranus_coords_sf <- st_as_sf(x = sumatranus_coords,
                              coords = c("longitude", "latitude"),
                              crs = 4326)

all_spp_coords_sf <- st_as_sf(x = all_spp_coords,
                              coords = c("longitude", "latitude"),
                              crs = 4326)

# Check CRS:
# indicus_coords_sf %>% st_crs()
```

```{r}
# Read in shapefile
range <- read_sf(here("redlist_species_data", "data_0.shp"))

# Check crs
#crs(range)

# Crop coordinates by species range file
cropped_indicus_coords <- indicus_coords_sf[range, op = st_intersects]

cropped_maximus_coords <- maximus_coords_sf[range, op = st_intersects]

cropped_sumatranus_coords <- sumatranus_coords_sf[range, op = st_intersects]

cropped_all_spp_coords <- all_spp_coords_sf[range, op = st_intersects]
```

```{r}
# save to Google Drive
write_csv(cropped_indicus_coords, "/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/R_files/R_output_data/occurrence_points/cropped_indicus_coords_draft.csv") # overwrite = FALSE prevents from overwriting
```

### Map occurrence data

```{r}
tmap_mode(mode = "view")

asian_elephant_map <-
  tm_shape(cropped_indicus_coords) +
    tm_symbols(col = "red",
               size = 0.2,
               alpha = 0.75) +
  tm_shape(cropped_maximus_coords) +
    tm_symbols(col = "green",
               size = 0.2) +
  tm_shape(cropped_sumatranus_coords) +
    tm_symbols(col = "blue",
                size = 0.2)

asian_elephant_map
```

### Create Asian Continent Shapefile

```{r}
world_sp <- as(world, "Spatial")
world_sf <- st_as_sf(world_sp, "sf")

# filter countries to just those in Asia
asia_countries <- world_sf %>% 
  filter(continent == "Asia") %>% 
  #filter(name_long != )
  dplyr::select(name_long)

# merge countries to create one large polygon
asia <- st_combine(asia_countries)

# convert Asia to spatial polygon
asia_sp <- as_Spatial(asia, cast = TRUE)

# check crs
#crs(asia_sp)
```

### Chelsa comparison

The below codechunk only needs to be run one time unless the individual bioclimatic variables change. 
```{r}
# Crop CHELSA data to Asia shapefile
chelsa_uncropped_stack <- stack(paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/uncropped_CHELSA_data/CHELSA_bio_", c("1","2","5","6","12","13","14"), ".tif"))

chelsa_cropped <- crop(chelsa_uncropped_stack, asia_sp)

plot(chelsa_cropped[[1]])
plot(chelsa_cropped[[2]])
plot(chelsa_cropped[[3]])
plot(chelsa_cropped[[4]])
plot(chelsa_cropped[[5]])
plot(chelsa_cropped[[6]])
plot(chelsa_cropped[[7]])

# Aggregate layers and save to Google Drive
bios <- c(1,2,5,6,12,13,14)
layers <- 1:7

for (i in layers){
  r <- chelsa_cropped[[i]]
  agg <- aggregate(r, fact = 5, fun = mean)
  writeRaster(agg, paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/asia_cropped_CHELSA_data/asia_cropped_CHELSA_layer", i, ".tif"), overwrite = FALSE)
}
```

```{r}
# Call CHELSA data from Google Drive and stack aggregated CHELSA data

chelsa_aggregated_stack <- stack(paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/asia_cropped_CHELSA_data/asia_cropped_CHELSA_layer", c("1","2","5","6","12","13","14"), ".tif"))

#plot(chelsa_aggregated_stack[[1]])
#plot(chelsa_aggregated_stack[[2]])
#plot(chelsa_aggregated_stack[[3]])
#plot(chelsa_aggregated_stack[[4]])
#plot(chelsa_aggregated_stack[[5]])
#plot(chelsa_aggregated_stack[[6]])
#plot(chelsa_aggregated_stack[[7]])
```

```{r}
# need just lat/long values in two columns to use raster extract, also need separate lat/long columns for the spatial thin below
cropped_all_spp_coords <- cropped_all_spp_coords %>% # extract lat/long from geometry column in sf object
  dplyr::mutate(longitude = sf::st_coordinates(.)[,1],
                latitude = sf::st_coordinates(.)[,2])

cropped_all_spp_coords <- cropped_all_spp_coords[c("species", "longitude", "latitude")] # pull out species, lat, long columns

cropped_all_spp_coords <- st_set_geometry(cropped_all_spp_coords, NULL) # drop geometry column that remains
```

### Spatial thin

```{r}
# just doing 10 replicates for now, thinning to 10 km
all_spp_output <- spThin::thin(cropped_all_spp_coords, 'longitude', 'latitude', 'species',
                       thin.par = 10, # thinned to 10 km
                       reps = 10, # default on Wallace is 100, but run time is long, so a low number is good for testing
                       locs.thinned.list.return = TRUE, 
                       write.files = FALSE, 
                       verbose = FALSE)

# find the iteration that returns the max number of occurrences
all_spp_maxThin <- which(sapply(all_spp_output, nrow) == max(sapply(all_spp_output, nrow)))

# if there's more than one max, pick the first one
all_spp_maxThin <- all_spp_output[[ifelse(length(all_spp_maxThin) > 1, all_spp_maxThin[1], all_spp_maxThin)]]  

# subset data to those thinned records
all_spp_occs <- cropped_all_spp_coords[as.numeric(rownames(all_spp_maxThin)),]

# save occs to upload to Wallace if needed
         all_spp_occs_wallace <- all_spp_occs %>% 
           dplyr::select(species, longitude, latitude) # change order to match
```

```{r}
# need just lat/long values in two columns to use raster extract
all_spp_occs_xy <- all_spp_occs[c('longitude', 'latitude')] # get just lat/long for raster extract
```

```{r}
# extracting values
all_species_extract <- raster::extract(chelsa_aggregated_stack, all_spp_occs_xy)

# add columns species, lat, long
all_species_extract_final <- cbind(all_spp_occs, all_species_extract)

library(Hmisc)
all_spp_extract_sub_matrix <- as.matrix(all_species_extract)
rcorr(all_spp_extract_sub_matrix, type="pearson") # type can be pearson or spearman
```

### Create graphs

CHELSA 1
```{r}
chelsa_1_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_1 = mean(asia_cropped_CHELSA_layer1))

chelsa_1_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_1 = sd(asia_cropped_CHELSA_layer1))

p1 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer1, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer1),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_1_mean, # Add mean
                aes(x = species, y = mean_1)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 1", title = "Mean Annual Air Temp 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p1
```

CHELSA 2
```{r}
chelsa_2_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_2 = mean(asia_cropped_CHELSA_layer2))

chelsa_2_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_2 = sd(asia_cropped_CHELSA_layer2))

p2 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer2, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer2),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_2_mean, # Add mean
                aes(x = species, y = mean_2)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 2", title = "Mean Diurnal Air Temp Range 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p2
```

CHELSA 5
```{r}
chelsa_5_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_5 = mean(asia_cropped_CHELSA_layer5))

chelsa_5_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_5 = sd(asia_cropped_CHELSA_layer5))

p5 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer5, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer5),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_5_mean, # Add mean
                aes(x = species, y = mean_5)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 5", title = "Mean Daily Max Air Temp of Warmest Month 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p5
```

CHELSA 6
```{r}
chelsa_6_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_6 = mean(asia_cropped_CHELSA_layer6))

chelsa_6_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_6 = sd(asia_cropped_CHELSA_layer6))

p6 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer6, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer6),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_6_mean, # Add mean
                aes(x = species, y = mean_6)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 6", title = "Mean Daily Min Air Temp of Coldest Month 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p6
```

CHELSA 12
```{r}
chelsa_12_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_12 = mean(asia_cropped_CHELSA_layer12))

chelsa_12_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_12 = sd(asia_cropped_CHELSA_layer12))

p12 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer12, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer12),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_12_mean, # Add mean
                aes(x = species, y = mean_12)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 12", title = "Annual Precip 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p12
```

CHELSA 13
```{r}
chelsa_13_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_13 = mean(asia_cropped_CHELSA_layer13))

chelsa_13_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_13 = sd(asia_cropped_CHELSA_layer13))

p13 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer13, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer13),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_13_mean, # Add mean
                aes(x = species, y = mean_13)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 13", title = "Precip Amount of the Wettest Month 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p13
```

CHELSA 14
```{r}
chelsa_14_mean <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_14 = mean(asia_cropped_CHELSA_layer14))

chelsa_14_sd <- all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_14 = sd(asia_cropped_CHELSA_layer14))

p14 <- ggplot() +
  geom_quasirandom(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer14, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer14),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_14_mean, # Add mean
                aes(x = species, y = mean_14)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 14", title = "Precip Amount of the Driest Month 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p14
```

