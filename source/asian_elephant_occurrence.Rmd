---
title: "Asian Elephant Occurrence Data"
author: "Grace Kumaishi"
date: "1/19/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
library(tidyverse)
library(rgbif) # interface to GBIF
library(maptools)
library(dismo)
library(rgeos)
library(viridis)
#library(scrubr)
library(raster)
#library(DHARMa) # something is wrong when I try to install/load
library(spocc) # Interface to species occurrence data sources
library(sf)
library(sp)
library(rgdal)
library(spData)
library(here)
library(lubridate)
library(kableExtra)
library(tmap)
library(here)
library(dplyr)
library(ggplot2)
library(ggbeeswarm)
library(patchwork)
#library(spThin)

#install wallace
library(wallace)

#load Wallace functions
source(system.file('shiny/funcs', 'functions.R', package = 'wallace'))
```

This does not need to be run again unless we're changing the input settings to create and thin our occurrence data. All occurrence results are saved as csv's and can be read in with the other Rmd.

## Description:

This markdown file outlines the first steps for creating data for species distribution modeling (SDM) with Wallace.

### Download species occurence data and get coordinates

We begin by downloading the species occurrence points for the Asian Elephant subspecies using Wallace's spocc:occ() function. Choose which chunk to run based on the species of interest.

Indian Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus indicus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus indicus")]]

# select just the necessary information
indicus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_indicus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

Sri Lankan Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus maximus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus maximus")]]

# select just the necessary information
maximus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_maximus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

Sumatran Elephant
```{r}
# Gives global records.  If limit is set high, this function can take a while to run.
results <- spocc::occ(query = "Elephas maximus sumatranus", # scientific name
                      from = "gbif", # set to records from https://www.gbif.org/
                      limit = 15000, # max number of records
                      has_coords = TRUE) # gets the lat/long for each observation

# select just GBIF records, format the species name
results[["gbif"]]$data[[formatSpName("Elephas maximus sumatranus")]]

# select just the necessary information
sumatranus_coords <- as.data.frame(results$gbif$data$Elephas_maximus_sumatranus) %>% # using GBIF data
  dplyr::select(longitude, latitude, occurrenceStatus, coordinateUncertaintyInMeters, institutionCode, references, basisOfRecord, eventDate) %>%  # selecting just the columns that we want
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "PRESERVED_SPECIMEN", "LIVING_SPECIMEN"),
         occurrenceStatus == "PRESENT",
        eventDate <= "2021-12-31" & eventDate >= "1981-01-01")
```

### Clean Data

```{r}
# remove rows with duplicate coordinates
occs.dups <- duplicated(indicus_coords[c('longitude', 'latitude')])
indicus_coords <- indicus_coords[!occs.dups,]

occs.dups <- duplicated(maximus_coords[c('longitude', 'latitude')])
maximus_coords <- maximus_coords[!occs.dups,]

occs.dups <- duplicated(sumatranus_coords[c('longitude', 'latitude')])
sumatranus_coords <- sumatranus_coords[!occs.dups,]

# make sure latitude and longitude are numeric (sometimes they are characters)
indicus_coords$latitude <- as.numeric(indicus_coords$latitude)
indicus_coords$longitude <- as.numeric(indicus_coords$longitude)

maximus_coords$latitude <- as.numeric(maximus_coords$latitude)
maximus_coords$longitude <- as.numeric(maximus_coords$longitude)

sumatranus_coords$latitude <- as.numeric(sumatranus_coords$latitude)
sumatranus_coords$longitude <- as.numeric(sumatranus_coords$longitude)

# give all records a unique ID
indicus_coords$occID <- row.names(indicus_coords)
maximus_coords$occID <- row.names(maximus_coords)
sumatranus_coords$occID <- row.names(sumatranus_coords)

# add species column to each dataset
indicus_coords$species <- "Indian elephant" 
  
indicus_coords <- indicus_coords %>% 
  relocate(species, .before = longitude)

maximus_coords$species <- "Sri Lankan elephant" 
  
maximus_coords <- maximus_coords %>% 
  relocate(species, .before = longitude)

sumatranus_coords$species <- "Sumatran elephant" 
  
sumatranus_coords <- sumatranus_coords %>% 
  relocate(species, .before = longitude)

# combine three species into single dataframe

all_spp_coords <- rbind(indicus_coords, maximus_coords, sumatranus_coords) 
```

### Crop data by species range

```{r}
# Turn data frames into sf object in order to crop by range shapefile
# indicus_coords_sf <- st_as_sf(x = indicus_coords,
#                               coords = c("longitude", "latitude"),
#                               crs = 4326)
# 
# maximus_coords_sf <- st_as_sf(x = maximus_coords,
#                               coords = c("longitude", "latitude"),
#                               crs = 4326)
# 
# sumatranus_coords_sf <- st_as_sf(x = sumatranus_coords,
#                               coords = c("longitude", "latitude"),
#                               crs = 4326)

all_spp_coords_sf <- st_as_sf(x = all_spp_coords,
                              coords = c("longitude", "latitude"), 
                              crs = 4326)

# Check CRS:
# all_spp_coords_sf %>% st_crs()
```

```{r}
# Read in shapefile
range <- read_sf(here("redlist_species_data", "data_0.shp"))

# Check crs
#crs(range)

# Crop coordinates by species range file
# cropped_indicus_coords <- indicus_coords_sf[range, op = st_intersects]
# 
# cropped_maximus_coords <- maximus_coords_sf[range, op = st_intersects]
# 
# cropped_sumatranus_coords <- sumatranus_coords_sf[range, op = st_intersects]

cropped_all_spp_coords <- all_spp_coords_sf[range, op = st_intersects]
```

```{r}
# save to Google Drive
#write_csv(cropped_indicus_coords, "/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/R_files/R_output_data/occurrence_points/cropped_all_spp_coords.csv") # overwrite = FALSE prevents from overwriting
```

### Map occurrence data

```{r}
# tmap_mode(mode = "view")
# 
# asian_elephant_map <-
#   tm_shape(cropped_indicus_coords) +
#     tm_symbols(col = "red",
#                size = 0.2,
#                alpha = 0.75) +
#   tm_shape(cropped_maximus_coords) +
#     tm_symbols(col = "green",
#                size = 0.2) +
#   tm_shape(cropped_sumatranus_coords) +
#     tm_symbols(col = "blue",
#                 size = 0.2)
# 
# asian_elephant_map
```

### Create Asian Continent Shapefile

```{r}
# world_sp <- as(world, "Spatial")
# world_sf <- st_as_sf(world_sp, "sf")
# 
# # filter countries to just those in Asia
# asia_countries <- world_sf %>% 
#   filter(continent == "Asia") %>% 
#   #filter(name_long != )
#   dplyr::select(name_long)
# 
# # merge countries to create one large polygon
# asia <- st_combine(asia_countries)
# 
# # convert Asia to spatial polygon
# asia_sp <- as_Spatial(asia, cast = TRUE)
# 
# # check crs
# #crs(asia_sp)
```

Using WWF Terrestrial Ecoregions
```{r}
# Get spatial extent using IndoMalay ecoregion from WWF. Data downloaded from: https://www.worldwildlife.org/publications/terrestrial-ecoregions-of-the-world

indomalay_region <- read_sf(dsn = "/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/R_files/R_input_data/wwf_ecoregions/official", layer = "wwf_terr_ecos") %>% 
   filter(REALM == "IM")

#check crs
crs(indomalay_region) #+proj=longlat +datum=WGS84 +no_defs 

indomalay_region_sp <- as_Spatial(indomalay_region, cast = TRUE)

# Create shapefile for wallace

# st_write(indomalay_region, dsn = "/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/R_files/R_output_data/indomalay_region/indomalay_region.shp", layer = "indomalay_region.shp", driver = "ESRI Shapefile")

# plot(indomalay_region)
```


### Chelsa comparison

The below codechunk only needs to be run one time unless the individual bioclimatic variables change. 
```{r}
library(terra)

# Crop CHELSA data to Asia shapefile
chelsa_uncropped_stack <- stack(paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/uncropped_CHELSA_data/CHELSA_bio_", c("1","2","3","4","7","10","11","12","15","16","17"), ".tif"))

chelsa_cropped <- terra::crop(chelsa_uncropped_stack, indomalay_region_sp)

#plot(chelsa_cropped[[1]])
#plot(chelsa_cropped[[2]])
#plot(chelsa_cropped[[3]])
#plot(chelsa_cropped[[4]])
#plot(chelsa_cropped[[5]])
#plot(chelsa_cropped[[6]])
#plot(chelsa_cropped[[7]])

# Aggregate layers and save to Google Drive
bios <- c(1,2,3,4,7,10,11,12,15,16,17)
layers <- 1:11

for (i in layers){
  r <- chelsa_cropped[[i]]
  agg <- aggregate(r, fact = 5, fun = mean)
  writeRaster(agg, paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/asia_cropped_CHELSA_data/asia_cropped_CHELSA_layer", i, ".tif"), overwrite = TRUE)
}

# Now you must manually change the bioclim numbers in the saved files in the Google Drive
```

```{r}
# Call CHELSA data from Google Drive and stack aggregated CHELSA data

chelsa_aggregated_stack <- stack(paste0("/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Chelsa_Data/asia_cropped_CHELSA_data/asia_cropped_CHELSA_layer", c("1","2","3","4","7","10","11","12","15","16","17"), ".tif"))

#plot(chelsa_aggregated_stack[[1]])
#plot(chelsa_aggregated_stack[[2]])
#plot(chelsa_aggregated_stack[[3]])
#plot(chelsa_aggregated_stack[[4]])
#plot(chelsa_aggregated_stack[[5]])
#plot(chelsa_aggregated_stack[[6]])
#plot(chelsa_aggregated_stack[[7]])
```

```{r}
# need just lat/long values in two columns to use raster extract, also need separate lat/long columns for the spatial thin below
cropped_all_spp_coords <- cropped_all_spp_coords %>% # extract lat/long from geometry column in sf object
  dplyr::mutate(longitude = sf::st_coordinates(.)[,1],
                latitude = sf::st_coordinates(.)[,2])

cropped_all_spp_coords <- cropped_all_spp_coords[c("species", "longitude", "latitude")] # pull out species, lat, long columns

cropped_all_spp_coords <- st_set_geometry(cropped_all_spp_coords, NULL) # drop geometry column that remains
```

### Spatial thin

```{r}
# just doing 10 replicates for now, thinning to 10 km
all_spp_output <- spThin::thin(cropped_all_spp_coords, 'longitude', 'latitude', 'species',
                       thin.par = 10, # thinned to 10 km
                       reps = 10, # default on Wallace is 100, but run time is long, so a low number is good for testing
                       locs.thinned.list.return = TRUE, 
                       write.files = FALSE, 
                       verbose = FALSE)

# find the iteration that returns the max number of occurrences
all_spp_maxThin <- which(sapply(all_spp_output, nrow) == max(sapply(all_spp_output, nrow)))

# if there's more than one max, pick the first one
all_spp_maxThin <- all_spp_output[[ifelse(length(all_spp_maxThin) > 1, all_spp_maxThin[1], all_spp_maxThin)]]  

# subset data to those thinned records
thinned_all_spp_occs <- cropped_all_spp_coords[as.numeric(rownames(all_spp_maxThin)),]

thinned_all_spp_occs_sf <- st_as_sf(x = thinned_all_spp_occs,
                              coords = c("longitude", "latitude"), 
                              crs = 4326)

# make sure that occs fall within WWF ecoregion
final_thinned_all_spp_occs <- thinned_all_spp_occs_sf[indomalay_region, op = st_intersects]

final_thinned_all_spp_occs <- final_thinned_all_spp_occs %>% 
  dplyr::mutate(longitude = sf::st_coordinates(.)[,1],
                latitude = sf::st_coordinates(.)[,2])

final_thinned_all_spp_occs <- st_set_geometry(final_thinned_all_spp_occs, NULL)

# rename species column to "name"
final_thinned_all_spp_occs <- as_tibble(final_thinned_all_spp_occs) %>% 
  dplyr::rename(name = species)

# # save occs to upload to Wallace if needed
#          all_spp_occs_wallace <- all_spp_occs %>% 
#            dplyr::select(species, longitude, latitude) # change order to match
```

```{r}
# save occs to Google Drive
write_csv(final_thinned_all_spp_occs, "/Volumes/GoogleDrive/.shortcut-targets-by-id/1YB-Hz3L-kWyiZMg2UM89GQkvqXyZUW1H/HWC_data/Data/Asian_Elephant/final_thinned_all_spp_occs.csv") # overwrite = FALSE prevents from overwriting
```

```{r}
# Graph thinned occs

thinned_all_spp_occs_sf <- st_as_sf(x = thinned_all_spp_occs,
                              coords = c("longitude", "latitude"),
                              crs = 4326)

tmap_mode(mode = "view")

thinned_asian_elephant_map <-
  tm_shape(thinned_all_spp_occs_sf) +
    tm_symbols(col = "species",
               size = 0.2,
               alpha = 0.75)

thinned_asian_elephant_map
```

```{r}
# need just lat/long values in two columns to use raster extract
thinned_all_spp_occs_xy <- thinned_all_spp_occs[c('longitude', 'latitude')] # get just lat/long for raster extract
```

```{r}
# extracting values
thinned_all_species_extract <- raster::extract(chelsa_aggregated_stack, thinned_all_spp_occs_xy)

# add columns species, lat, long
thinned_all_species_extract_final <- cbind(thinned_all_spp_occs, thinned_all_species_extract)

library(Hmisc)
thinned_all_spp_extract_sub_matrix <- as.matrix(thinned_all_species_extract)
rcorr(thinned_all_spp_extract_sub_matrix, type="pearson") # type can be pearson or spearman
```

### Create graphs

CHELSA 1
```{r}
chelsa_1_mean <- thinned_all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_1 = mean(asia_cropped_CHELSA_layer1))

chelsa_1_sd <- thinned_all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_1 = sd(asia_cropped_CHELSA_layer1))

p1 <- ggplot() +
  geom_quasirandom(data = thinned_all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer1, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = thinned_all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer1),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_1_mean, # Add mean
                aes(x = species, y = mean_1)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 1", title = "Mean Annual Air Temp 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p1
```

CHELSA 2
```{r}
chelsa_2_mean <- thinned_all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(mean_2 = mean(asia_cropped_CHELSA_layer2))

chelsa_2_sd <- thinned_all_species_extract_final %>% 
  group_by(species) %>% 
  summarise(sd_2 = sd(asia_cropped_CHELSA_layer2))

p2 <- ggplot() +
  geom_quasirandom(data = thinned_all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer2, color = species),
                size = 2,
                alpha = 0.5) +
  geom_jitter() +
  geom_boxplot(data = thinned_all_species_extract_final,
                aes(x = species, y = asia_cropped_CHELSA_layer2),
                width = 0.3,
                size = 0.5,
                alpha = 0) +
  geom_point(data = chelsa_2_mean, # Add mean
                aes(x = species, y = mean_2)) +
  theme_minimal() +
  labs(x = "Species", y = "CHELSA 2", title = "Mean Diurnal Air Temp Range 1981-2021") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

p2
```
